{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertForMaskedLM, DistilBertTokenizerFast\n",
    "from transformers import PretrainedConfig\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "model = DistilBertForMaskedLM.from_pretrained(\"./model_dbertft/\", from_tf=True)\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"The capital of France, {} , contains the Eiffel Tower, a very popular tourist attraction.\"\n",
    "\n",
    "# vector_input = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "\n",
    "# probabilities = model(vector_input)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_news_list, get_users_list\n",
    "\n",
    "news = get_news_list()\n",
    "users = get_users_list()\n",
    "\n",
    "users_dict = {}\n",
    "for user in users:\n",
    "    users_dict[user.user_id] = user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import get_cosine_similarity, get_user_embeddings, get_news_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_embeddings, current_embeddings = get_user_embeddings(news[:30], news[0])\n",
    "\n",
    "get_cosine_similarity(historical_embeddings[0], current_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nDCG25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "test_batches = joblib.load(\"test_batches.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in test_batches.keys():\n",
    "    print(users_dict[user].train_list)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "final_results = {}\n",
    "with tqdm(total=len(test_batches)) as pbar:\n",
    "    for user_key, batch in test_batches.items():\n",
    "        pbar.update(1)\n",
    "        test_batch_news_text, test_batch_isread, test_batch_key = batch[\"news_texts\"] , batch[\"news_is_relevant\"], batch[\"key\"]\n",
    "        historical_embeddings = None\n",
    "        scores = []\n",
    "        historical_news = users_dict[user_key].train_list[:5]\n",
    "        for news in test_batch_news_text:\n",
    "            current_news = news\n",
    "            historical_embeddings, current_embeddings = get_user_embeddings(historical_news, current_news, historical_embeddings)\n",
    "            scores.append(get_cosine_similarity(historical_embeddings[0], current_embeddings[0]))\n",
    "        scores = np.array(scores)\n",
    "        final_results[user_key] = [(key, score, is_relevant) for key, score, is_relevant in zip(test_batch_key, scores, test_batch_isread)]\n",
    "        joblib.dump(final_results, \"ranking_dbertft.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "ndcg_score(is_relevant.reshape(1, -1), scores.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recom-articles",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
